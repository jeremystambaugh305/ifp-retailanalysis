{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **ETL.ipynb**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* \"Fetch data from Kaggle and save as raw data\", \n",
        "NB I have downloaded the datasets as a zip file, extracted and saved them in Windows Explorer for now, will add this extraction step later if required and I have time.\n",
        "\n",
        "* Read and summarise, analyse and visualise datasets.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* \n",
        "sales data-set.csv\n",
        "Features data set.csv\n",
        "stores data-set.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Write here which files, code or artefacts you generate by the end of the notebook \n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* If you have any additional comments that don't fit in the previous bullets, please state them here. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* I will store the notebooks in a subfolder, therefore when running the notebook in the editor, I need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "* Access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\jerem\\\\OneDrive\\\\Documents\\\\CodeInstitute\\\\vscode-projects\\\\ifp-retailanalysis\\\\jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "Make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\jerem\\\\OneDrive\\\\Documents\\\\CodeInstitute\\\\vscode-projects\\\\ifp-retailanalysis'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Section 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import necessary Python libraries, read raw datasets into Pandas dataframes and inspect summary data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note I downloaded the csv files as a zip file from Kaggle, unzipped the archive on my downloads folder, renamed the files replacing spaces with underscores, dragged them from my downloads extract folder saved the datasets.  I do not know how to import them directly from the Kaggle website and unzip the archive, either with code here or in the vscode terminal but would seek to learn and do this if possible to ensure no corruption of datasets or if downloading to Windows vs vscode causes any auto reformating of dates from US to UK format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import all necessary Python libraries\n",
        "import numpy\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#reset display max rows to default after expanding below for readability and to limit file size\n",
        "pd.reset_option('display.max_rows')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<sales_data-set.csv> read into data frame \"df_sales\"\n",
            "\n",
            "        Store  Dept        Date  Weekly_Sales  IsHoliday\n",
            "0           1     1  05/02/2010      24924.50      False\n",
            "1           1     1  12/02/2010      46039.49       True\n",
            "2           1     1  19/02/2010      41595.55      False\n",
            "3           1     1  26/02/2010      19403.54      False\n",
            "4           1     1  05/03/2010      21827.90      False\n",
            "...       ...   ...         ...           ...        ...\n",
            "421565     45    98  28/09/2012        508.37      False\n",
            "421566     45    98  05/10/2012        628.10      False\n",
            "421567     45    98  12/10/2012       1061.02      False\n",
            "421568     45    98  19/10/2012        760.01      False\n",
            "421569     45    98  26/10/2012       1076.80      False\n",
            "\n",
            "[421570 rows x 5 columns]\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 421570 entries, 0 to 421569\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count   Dtype  \n",
            "---  ------        --------------   -----  \n",
            " 0   Store         421570 non-null  int64  \n",
            " 1   Dept          421570 non-null  int64  \n",
            " 2   Date          421570 non-null  object \n",
            " 3   Weekly_Sales  421570 non-null  float64\n",
            " 4   IsHoliday     421570 non-null  bool   \n",
            "dtypes: bool(1), float64(1), int64(2), object(1)\n",
            "memory usage: 13.3+ MB\n",
            "None\n",
            "\n",
            "\n",
            "<Features data_set.csv> read into data frame \"df_features\"\n",
            "\n",
            "      Store        Date  Temperature  Fuel_Price  MarkDown1  MarkDown2  \\\n",
            "0         1  05/02/2010        42.31       2.572        NaN        NaN   \n",
            "1         1  12/02/2010        38.51       2.548        NaN        NaN   \n",
            "2         1  19/02/2010        39.93       2.514        NaN        NaN   \n",
            "3         1  26/02/2010        46.63       2.561        NaN        NaN   \n",
            "4         1  05/03/2010        46.50       2.625        NaN        NaN   \n",
            "...     ...         ...          ...         ...        ...        ...   \n",
            "8185     45  28/06/2013        76.05       3.639    4842.29     975.03   \n",
            "8186     45  05/07/2013        77.50       3.614    9090.48    2268.58   \n",
            "8187     45  12/07/2013        79.37       3.614    3789.94    1827.31   \n",
            "8188     45  19/07/2013        82.84       3.737    2961.49    1047.07   \n",
            "8189     45  26/07/2013        76.06       3.804     212.02     851.73   \n",
            "\n",
            "      MarkDown3  MarkDown4  MarkDown5         CPI  Unemployment  IsHoliday  \n",
            "0           NaN        NaN        NaN  211.096358         8.106      False  \n",
            "1           NaN        NaN        NaN  211.242170         8.106       True  \n",
            "2           NaN        NaN        NaN  211.289143         8.106      False  \n",
            "3           NaN        NaN        NaN  211.319643         8.106      False  \n",
            "4           NaN        NaN        NaN  211.350143         8.106      False  \n",
            "...         ...        ...        ...         ...           ...        ...  \n",
            "8185       3.00    2449.97    3169.69         NaN           NaN      False  \n",
            "8186     582.74    5797.47    1514.93         NaN           NaN      False  \n",
            "8187      85.72     744.84    2150.36         NaN           NaN      False  \n",
            "8188     204.19     363.00    1059.46         NaN           NaN      False  \n",
            "8189       2.06      10.88    1864.57         NaN           NaN      False  \n",
            "\n",
            "[8190 rows x 12 columns]\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8190 entries, 0 to 8189\n",
            "Data columns (total 12 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Store         8190 non-null   int64  \n",
            " 1   Date          8190 non-null   object \n",
            " 2   Temperature   8190 non-null   float64\n",
            " 3   Fuel_Price    8190 non-null   float64\n",
            " 4   MarkDown1     4032 non-null   float64\n",
            " 5   MarkDown2     2921 non-null   float64\n",
            " 6   MarkDown3     3613 non-null   float64\n",
            " 7   MarkDown4     3464 non-null   float64\n",
            " 8   MarkDown5     4050 non-null   float64\n",
            " 9   CPI           7605 non-null   float64\n",
            " 10  Unemployment  7605 non-null   float64\n",
            " 11  IsHoliday     8190 non-null   bool   \n",
            "dtypes: bool(1), float64(9), int64(1), object(1)\n",
            "memory usage: 712.0+ KB\n",
            "None\n",
            "\n",
            "\n",
            "<stores_data-set.csv> read into data frame \"df_stores\"\n",
            "\n",
            "    Store Type    Size\n",
            "0       1    A  151315\n",
            "1       2    A  202307\n",
            "2       3    B   37392\n",
            "3       4    A  205863\n",
            "4       5    B   34875\n",
            "5       6    A  202505\n",
            "6       7    B   70713\n",
            "7       8    A  155078\n",
            "8       9    B  125833\n",
            "9      10    B  126512\n",
            "10     11    A  207499\n",
            "11     12    B  112238\n",
            "12     13    A  219622\n",
            "13     14    A  200898\n",
            "14     15    B  123737\n",
            "15     16    B   57197\n",
            "16     17    B   93188\n",
            "17     18    B  120653\n",
            "18     19    A  203819\n",
            "19     20    A  203742\n",
            "20     21    B  140167\n",
            "21     22    B  119557\n",
            "22     23    B  114533\n",
            "23     24    A  203819\n",
            "24     25    B  128107\n",
            "25     26    A  152513\n",
            "26     27    A  204184\n",
            "27     28    A  206302\n",
            "28     29    B   93638\n",
            "29     30    C   42988\n",
            "30     31    A  203750\n",
            "31     32    A  203007\n",
            "32     33    A   39690\n",
            "33     34    A  158114\n",
            "34     35    B  103681\n",
            "35     36    A   39910\n",
            "36     37    C   39910\n",
            "37     38    C   39690\n",
            "38     39    A  184109\n",
            "39     40    A  155083\n",
            "40     41    A  196321\n",
            "41     42    C   39690\n",
            "42     43    C   41062\n",
            "43     44    C   39910\n",
            "44     45    B  118221\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 45 entries, 0 to 44\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Store   45 non-null     int64 \n",
            " 1   Type    45 non-null     object\n",
            " 2   Size    45 non-null     int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 1.2+ KB\n",
            "None\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#read sales, Features and Store datasets into aptly named pandas dataframes and summarise\n",
        " \n",
        "# I attempted to read from zip in case it affects date format but was not possible\n",
        "# df_sales=pd.read_csv('Dataset/Raw/archive.zip/sales data-set.csv')\n",
        "\n",
        "df_sales=pd.read_csv('Dataset/Raw/sales_data-set.csv')\n",
        "print(f'<sales_data-set.csv> read into data frame \"df_sales\"\\n')\n",
        "print(f'{df_sales}\\n')\n",
        "print(f'{df_sales.info()}\\n\\n')\n",
        "\n",
        "df_features=pd.read_csv('Dataset/Raw/Features_data set.csv')\n",
        "print(f'<Features data_set.csv> read into data frame \"df_features\"\\n')\n",
        "print(f'{df_features}\\n')\n",
        "print(f'{df_features.info()}\\n\\n')\n",
        "\n",
        "df_stores=pd.read_csv('Dataset/Raw/stores_data-set.csv')\n",
        "print(f'<stores_data-set.csv> read into data frame \"df_stores\"\\n')\n",
        "print(f'{df_stores}\\n')\n",
        "print(f'{df_stores.info()}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "My initial observations. \n",
        "\n",
        "1. The sales dataset is by far the largest with, for each store and each department within, on dates apparently from 5th Feb 2010 to 26th Oct 2012 (TBC by date formatting and sorting) The dates seen in the head and tail are clearly in UK date format dd/mm/yyyy which surprised me this being a USA dataset.\n",
        "\n",
        "Start date is in line with the Kaggle data source description 'Historical sales data, which covers to 2010-02-05 to 2012-11-01' but but end date is slightly earlier possibly due to dates not being sorted correctly., weekly sales data and whether each date is a holiday.  \n",
        "\n",
        "The there is no missing data.\n",
        "\n",
        "There are no units in the column headings so it's not immediately clear what the weekly_sales represent.  At this stage I will assume these are the total amounts in US dollars as the description of holidays in the Kaggle dataset implies this is a USA business.\n",
        "\n",
        "2. The Features dataset is considerably smaller being only by store not department.  Like the sales data, it appears to have weekly information starting 5th Feb 2010 but for a longer date range to 26th Jul 2013, and whether each date is a holiday.  \n",
        "But unlike the sales data, it has additonal data on Markdowns 1-5, temperature, fuel price, CPI and unemployment.\n",
        "\n",
        "Again, The dates seen in the head and tail are clearly in UK date format dd/mm/yyyy which surprised me this being a USA dataset.\n",
        "\n",
        "There is a considerable amount of missing data including Markdown data for almost half the rows.\n",
        "\n",
        "There are no units in the column headings so it's not immediately clear what the numbers in the Markdown columns represent.  At this stage I will assume these are the total amounts in US dollars as with weekly_sales as they seem mostly too large to be percentages.\n",
        "\n",
        "Regarding dates, as in section 1 I downloaded the dataset as a zip archive from Kaggle, renamed replacing spaces with underscores and dragged the files into the vscode Datasets/Raw folder (all without opening in Excel or any other software).  However I am unsure if downloading and extracting on my UK computer or possibly vscode settings could have still somehow reformatted dates to UK format if they were in US format.  The dates in the sales and features datasets appeared to me of mixed format so converting using the datetime format with the datefirst=True argument is risky so I would need to inspect dates not already in a date format to check.\n",
        "\n",
        "3. The sales dataset is relatively small just listing the store type (a letter) and size (an integer) for each of the 45 stores.\n",
        "\n",
        "There is no missing data.\n",
        "\n",
        "Again no units for size so no idea if this is annual turnover or square footage etc.  I'd guess the former it has a close correlation with sales. \n",
        "\n",
        "In order to better understand the datasets from the outset, would normally request information on the units from the generator of the datasets but in this project that is not possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Section 2 Initial visualisations and transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2.1 visualise total sales distribution and sales vs size correlation by store type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Store Type    Size  totalsales_millions\n",
            "20     21    B  140167           301.397792\n",
            "4       5    B   34875           299.543953\n",
            "14     15    B  123737           288.999911\n",
            "13     14    A  200898           286.517704\n",
            "2       3    B   37392           275.382441\n",
            "10     11    A  207499           271.617714\n",
            "27     28    A  206302           253.855917\n",
            "6       7    B   70713           223.756131\n",
            "1       2    A  202307           222.402809\n",
            "39     40    A  155083           207.445542\n",
            "19     20    A  203742           206.634862\n",
            "31     32    A  203007           199.613905\n",
            "23     24    A  203819           198.750618\n",
            "24     25    B  128107           194.016021\n",
            "11     12    B  112238           193.962787\n",
            "28     29    B   93638           189.263681\n",
            "41     42    C   39690           181.341935\n",
            "32     33    A   39690           166.819246\n",
            "18     19    A  203819           155.114734\n",
            "22     23    B  114533           147.075649\n",
            "12     13    A  219622           144.287230\n",
            "26     27    A  204184           143.416394\n",
            "34     35    B  103681           138.249763\n",
            "40     41    A  196321           137.870310\n",
            "35     36    A   39910           131.520672\n",
            "8       9    B  125833           129.951181\n",
            "17     18    B  120653           127.782139\n",
            "21     22    B  119557           108.117879\n",
            "25     26    A  152513           101.061179\n",
            "43     44    C   39910            90.565435\n",
            "15     16    B   57197            89.133684\n",
            "7       8    A  155078            81.598275\n",
            "42     43    C   41062            79.565752\n",
            "9      10    B  126512            77.789219\n",
            "29     30    C   42988            77.141554\n",
            "16     17    B   93188            74.252425\n",
            "37     38    C   39690            74.202740\n",
            "30     31    A  203750            62.716885\n",
            "3       4    A  205863            57.586735\n",
            "38     39    A  184109            55.159626\n",
            "36     37    C   39910            53.412215\n",
            "5       6    A  202505            45.475689\n",
            "44     45    B  118221            43.293088\n",
            "33     34    A  158114            37.160222\n",
            "0       1    A  151315                  NaN\n"
          ]
        }
      ],
      "source": [
        "#Create copy of df_stores called df_stores_T, aggregate total sales by store \n",
        "# from sales dataset and add column to df_stores_T.\n",
        "df_stores_T = df_stores.copy()\n",
        "df_stores_T['totalsales_millions'] = (\n",
        "    df_sales.groupby('Store')['Weekly_Sales'].sum()/1000000\n",
        "    )\n",
        "print(df_stores_T.sort_values(by='totalsales_millions', ascending=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Size                              totalsales_millions                \\\n",
            "     count      mean    median      sum               count   mean median   \n",
            "Type                                                                        \n",
            "A       22  177247.7  202406.0  3899450                  21  150.8  144.3   \n",
            "B       17  101190.7  114533.0  1720242                  17  170.7  147.1   \n",
            "C        6   40541.7   39910.0   243250                   6   92.7   78.4   \n",
            "\n",
            "              \n",
            "         sum  \n",
            "Type          \n",
            "A     3166.6  \n",
            "B     2902.0  \n",
            "C      556.2  \n",
            "\n",
            "\n",
            "Correlation matrix for store type A:\n",
            "                         Size  totalsales_millions\n",
            "Size                 1.000000             0.141003\n",
            "totalsales_millions  0.141003             1.000000\n",
            "\n",
            "Correlation matrix for store type B:\n",
            "                         Size  totalsales_millions\n",
            "Size                 1.000000            -0.273291\n",
            "totalsales_millions -0.273291             1.000000\n",
            "\n",
            "Correlation matrix for store type C:\n",
            "                         Size  totalsales_millions\n",
            "Size                 1.000000            -0.266931\n",
            "totalsales_millions -0.266931             1.000000\n"
          ]
        }
      ],
      "source": [
        "#Grouped store type count, mean and total Size and total sales.\n",
        "#Correlation matrices for sales vs size for each store type.\n",
        "print(df_stores_T.drop(columns=['Store']).groupby(\"Type\").agg(['count', 'mean', 'median', 'sum']).round(1))\n",
        "print()\n",
        "types= df_stores[\"Type\"].unique()\n",
        "for t in types:\n",
        "    print()\n",
        "    print(f'Correlation matrix for store type {t}:')\n",
        "    print(df_stores_T[df_stores_T[\"Type\"] == t].drop(columns=['Type','Store']).corr())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the above, there does not appear to be any very significant grouping of sales amongst any particular group of stores which the business should focus on. \n",
        "\n",
        "Store type A has the largest store count, mean and total sales, followed by type B with type C being the fewest and smallest.\n",
        "\n",
        "There is no strong correlation between store size and sales and in fact this is negative for store types B and C which seems counterintuitive indicating other factors more strongly affect sales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 2.12 join sales and Features datasets together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2.2 Reformat sales and Features dataframe date columns to datetime format and merge datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>Dept</th>\n",
              "      <th>Date</th>\n",
              "      <th>Weekly_Sales</th>\n",
              "      <th>IsHoliday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>24924.50</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>50605.27</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>13740.12</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>429</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>39954.04</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>572</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>32229.38</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421012</th>\n",
              "      <td>45</td>\n",
              "      <td>93</td>\n",
              "      <td>2012-10-26</td>\n",
              "      <td>2487.80</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421146</th>\n",
              "      <td>45</td>\n",
              "      <td>94</td>\n",
              "      <td>2012-10-26</td>\n",
              "      <td>5203.31</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421289</th>\n",
              "      <td>45</td>\n",
              "      <td>95</td>\n",
              "      <td>2012-10-26</td>\n",
              "      <td>56017.47</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421434</th>\n",
              "      <td>45</td>\n",
              "      <td>97</td>\n",
              "      <td>2012-10-26</td>\n",
              "      <td>6817.48</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421569</th>\n",
              "      <td>45</td>\n",
              "      <td>98</td>\n",
              "      <td>2012-10-26</td>\n",
              "      <td>1076.80</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>421570 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Store  Dept       Date  Weekly_Sales  IsHoliday\n",
              "0           1     1 2010-02-05      24924.50      False\n",
              "143         1     2 2010-02-05      50605.27      False\n",
              "286         1     3 2010-02-05      13740.12      False\n",
              "429         1     4 2010-02-05      39954.04      False\n",
              "572         1     5 2010-02-05      32229.38      False\n",
              "...       ...   ...        ...           ...        ...\n",
              "421012     45    93 2012-10-26       2487.80      False\n",
              "421146     45    94 2012-10-26       5203.31      False\n",
              "421289     45    95 2012-10-26      56017.47      False\n",
              "421434     45    97 2012-10-26       6817.48      False\n",
              "421569     45    98 2012-10-26       1076.80      False\n",
              "\n",
              "[421570 rows x 5 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_sales_T=df_sales.copy()\n",
        "df_sales_T['Date'] = pd.to_datetime(df_sales_T['Date'], errors='raise', dayfirst='True', format='mixed')\n",
        "# df_sales['Date'] = pd.to_datetime(df_sales['Date'], errors='raise', dayfirst='False')\n",
        "df_sales_T = df_sales_T.sort_values(by=['Date','Store', 'Dept'])\n",
        "df_sales_T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In converting the date formats in the sales and features dataframes with the pd.dateformat function, I used the errors='raise', dayfirst=True, format='mixed' arguments.  The format='mixed' argument was necessary, without which the code generated errors, presumably due to formatting inconsistencies in the raw data.  I assume all dates not already in obvious date format have day first as seems to be the case with the first and last few rows.  But I need to double check this later.\n",
        "\n",
        "According to the pandas documentation for the datetime function currently at\n",
        "https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html\n",
        "\n",
        "the “mixed” argument is 'used to infer the format for each element individually. This is risky, and you should probably use it along with dayfirst.'  I assumed = False as this is a USA dataset so any date strings are likely to state month number before day number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[<class 'str'>]\n"
          ]
        }
      ],
      "source": [
        "#check unique dtypes for Date column\n",
        "element_types = df_sales['Date'].apply(type).unique()\n",
        "print (element_types)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All dates are strings but I know from datetime reformatting above that not all are properly formatted so type='Mixed' is required when using dateformat function as explained above.  I don't know how to check which rows contain strings where date may be ambiguous.  Need to learn this later to find such rows and check dates properly converted.\n",
        "\n",
        "Same issue with original features dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[<class 'str'>]\n"
          ]
        }
      ],
      "source": [
        "#check unique dtypes for Date column\n",
        "element_types = df_features['Date'].apply(type).unique()\n",
        "print (element_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>Date</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Fuel_Price</th>\n",
              "      <th>MarkDown1</th>\n",
              "      <th>MarkDown2</th>\n",
              "      <th>MarkDown3</th>\n",
              "      <th>MarkDown4</th>\n",
              "      <th>MarkDown5</th>\n",
              "      <th>CPI</th>\n",
              "      <th>Unemployment</th>\n",
              "      <th>IsHoliday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>42.31</td>\n",
              "      <td>2.572</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>211.096358</td>\n",
              "      <td>8.106</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2730</th>\n",
              "      <td>16</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>19.79</td>\n",
              "      <td>2.580</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>189.381697</td>\n",
              "      <td>7.039</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5460</th>\n",
              "      <td>31</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>39.05</td>\n",
              "      <td>2.572</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>210.752605</td>\n",
              "      <td>8.324</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3640</th>\n",
              "      <td>21</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>39.05</td>\n",
              "      <td>2.572</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>210.752605</td>\n",
              "      <td>8.324</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4550</th>\n",
              "      <td>26</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>9.55</td>\n",
              "      <td>2.788</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>131.527903</td>\n",
              "      <td>8.488</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5823</th>\n",
              "      <td>32</td>\n",
              "      <td>2013-07-26</td>\n",
              "      <td>72.99</td>\n",
              "      <td>3.582</td>\n",
              "      <td>549.89</td>\n",
              "      <td>940.93</td>\n",
              "      <td>86.00</td>\n",
              "      <td>106.47</td>\n",
              "      <td>1530.56</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2365</th>\n",
              "      <td>13</td>\n",
              "      <td>2013-07-26</td>\n",
              "      <td>83.62</td>\n",
              "      <td>3.669</td>\n",
              "      <td>346.31</td>\n",
              "      <td>1377.41</td>\n",
              "      <td>93.40</td>\n",
              "      <td>140.32</td>\n",
              "      <td>2147.06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5641</th>\n",
              "      <td>31</td>\n",
              "      <td>2013-07-26</td>\n",
              "      <td>85.00</td>\n",
              "      <td>3.620</td>\n",
              "      <td>1394.82</td>\n",
              "      <td>138.71</td>\n",
              "      <td>12.00</td>\n",
              "      <td>970.77</td>\n",
              "      <td>6859.07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6733</th>\n",
              "      <td>37</td>\n",
              "      <td>2013-07-26</td>\n",
              "      <td>83.28</td>\n",
              "      <td>3.620</td>\n",
              "      <td>178.00</td>\n",
              "      <td>11.86</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>779.32</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8189</th>\n",
              "      <td>45</td>\n",
              "      <td>2013-07-26</td>\n",
              "      <td>76.06</td>\n",
              "      <td>3.804</td>\n",
              "      <td>212.02</td>\n",
              "      <td>851.73</td>\n",
              "      <td>2.06</td>\n",
              "      <td>10.88</td>\n",
              "      <td>1864.57</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8190 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Store       Date  Temperature  Fuel_Price  MarkDown1  MarkDown2  \\\n",
              "0         1 2010-02-05        42.31       2.572        NaN        NaN   \n",
              "2730     16 2010-02-05        19.79       2.580        NaN        NaN   \n",
              "5460     31 2010-02-05        39.05       2.572        NaN        NaN   \n",
              "3640     21 2010-02-05        39.05       2.572        NaN        NaN   \n",
              "4550     26 2010-02-05         9.55       2.788        NaN        NaN   \n",
              "...     ...        ...          ...         ...        ...        ...   \n",
              "5823     32 2013-07-26        72.99       3.582     549.89     940.93   \n",
              "2365     13 2013-07-26        83.62       3.669     346.31    1377.41   \n",
              "5641     31 2013-07-26        85.00       3.620    1394.82     138.71   \n",
              "6733     37 2013-07-26        83.28       3.620     178.00      11.86   \n",
              "8189     45 2013-07-26        76.06       3.804     212.02     851.73   \n",
              "\n",
              "      MarkDown3  MarkDown4  MarkDown5         CPI  Unemployment  IsHoliday  \n",
              "0           NaN        NaN        NaN  211.096358         8.106      False  \n",
              "2730        NaN        NaN        NaN  189.381697         7.039      False  \n",
              "5460        NaN        NaN        NaN  210.752605         8.324      False  \n",
              "3640        NaN        NaN        NaN  210.752605         8.324      False  \n",
              "4550        NaN        NaN        NaN  131.527903         8.488      False  \n",
              "...         ...        ...        ...         ...           ...        ...  \n",
              "5823      86.00     106.47    1530.56         NaN           NaN      False  \n",
              "2365      93.40     140.32    2147.06         NaN           NaN      False  \n",
              "5641      12.00     970.77    6859.07         NaN           NaN      False  \n",
              "6733        NaN        NaN     779.32         NaN           NaN      False  \n",
              "8189       2.06      10.88    1864.57         NaN           NaN      False  \n",
              "\n",
              "[8190 rows x 12 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_features_T=df_features.copy()\n",
        "df_features_T['Date'] = pd.to_datetime(df_features_T['Date'], errors='raise', dayfirst='True', format='mixed')\n",
        "df_features_T = df_features_T.sort_values(by=['Date'])\n",
        "df_features_T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Find and inspect dates which were in different formats in raw sales and Features datasets to ensure they converted to correct date when I have time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MarkDown1\n",
              "-2781.45      1\n",
              "-772.21       1\n",
              "-563.90       1\n",
              "-16.93        1\n",
              " 0.27         1\n",
              "             ..\n",
              " 84139.36     1\n",
              " 88646.76     1\n",
              " 88750.34     1\n",
              " 95102.50     1\n",
              " 103184.98    1\n",
              "Name: count, Length: 4023, dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#look at markdown ranges to try to understand what they mean  Are these percentages or absolute reductions?\n",
        "df_features_T['MarkDown1'].value_counts().sort_index(ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Year  Monthno  MarkDownOn  IsHoliday\n",
            "2010  2        False       False        135\n",
            "                           True          45\n",
            "      3        False       False        180\n",
            "      4        False       False        225\n",
            "      5        False       False        180\n",
            "      6        False       False        180\n",
            "      7        False       False        225\n",
            "      8        False       False        180\n",
            "      9        False       False        135\n",
            "                           True          45\n",
            "      10       False       False        225\n",
            "      11       False       False        135\n",
            "                           True          45\n",
            "      12       False       False        180\n",
            "                           True          45\n",
            "2011  1        False       False        180\n",
            "      2        False       False        135\n",
            "                           True          45\n",
            "      3        False       False        180\n",
            "      4        False       False        225\n",
            "      5        False       False        180\n",
            "      6        False       False        180\n",
            "      7        False       False        225\n",
            "      8        False       False        180\n",
            "      9        False       False        180\n",
            "                           True          45\n",
            "      10       False       False        180\n",
            "      11       False       False         45\n",
            "               True        False         90\n",
            "                           True          45\n",
            "      12       True        False        180\n",
            "                           True          45\n",
            "2012  1        True        False        180\n",
            "      2        True        False        135\n",
            "                           True          45\n",
            "      3        True        False        225\n",
            "      4        True        False        180\n",
            "      5        True        False        180\n",
            "      6        True        False        225\n",
            "      7        True        False        180\n",
            "      8        True        False        225\n",
            "      9        True        False        135\n",
            "                           True          45\n",
            "      10       True        False        180\n",
            "      11       True        False        180\n",
            "                           True          45\n",
            "      12       True        False        135\n",
            "                           True          45\n",
            "2013  1        True        False        180\n",
            "      2        True        False        135\n",
            "                           True          45\n",
            "      3        True        False        225\n",
            "      4        True        False        180\n",
            "      5        True        False        225\n",
            "      6        True        False        180\n",
            "      7        True        False        180\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#read and view features file to try to understand what Markdown columns mean\n",
        "\n",
        "pd.set_option('display.max_rows', 1000) # to read the whole output.  Should reset in next line.\n",
        "# ,1000 used rather than ,None to limit dangerously large display generation elsewhere and \n",
        "# file size if not reset.\n",
        "\n",
        "df_features_T['Year'] =df_features_T['Date'].dt.year\n",
        "df_features_T['Monthno'] =df_features_T['Date'].dt.month\n",
        "df_features_T['MarkDownOn']=((df_features_T['MarkDown1'] > 0) | (df_features_T['MarkDown2'] > 0) | (df_features_T['MarkDown3'] > 0) | (df_features_T['MarkDown4'] > 0) | (df_features_T['MarkDown5'] > 0))\n",
        "print(df_features_T.groupby(['Year', 'Monthno', 'MarkDownOn','IsHoliday']).size())\n",
        "\n",
        "# According to the summary below, there is only data for at least one of the \n",
        "# 5 MarkDown columns from Nov 2011 onwards  this is in line with the Kaggle sourcepage which said \n",
        "# there was in fact no markdown data until Nov 2011."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "#reset display max rows to default after expanding above for readability and to limit file size\n",
        "pd.reset_option('display.max_rows')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 2.3 Merge sales and features datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Store  Dept       Date  Weekly_Sales IsHoliday_x  Temperature  \\\n",
            "0           1   1.0 2010-02-05      24924.50       False        42.31   \n",
            "1           1   2.0 2010-02-05      50605.27       False        42.31   \n",
            "2           1   3.0 2010-02-05      13740.12       False        42.31   \n",
            "3           1   4.0 2010-02-05      39954.04       False        42.31   \n",
            "4           1   5.0 2010-02-05      32229.38       False        42.31   \n",
            "...       ...   ...        ...           ...         ...          ...   \n",
            "423320     32   NaN 2013-07-26           NaN         NaN        72.99   \n",
            "423321     13   NaN 2013-07-26           NaN         NaN        83.62   \n",
            "423322     31   NaN 2013-07-26           NaN         NaN        85.00   \n",
            "423323     37   NaN 2013-07-26           NaN         NaN        83.28   \n",
            "423324     45   NaN 2013-07-26           NaN         NaN        76.06   \n",
            "\n",
            "        Fuel_Price  MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5  \\\n",
            "0            2.572        NaN        NaN        NaN        NaN        NaN   \n",
            "1            2.572        NaN        NaN        NaN        NaN        NaN   \n",
            "2            2.572        NaN        NaN        NaN        NaN        NaN   \n",
            "3            2.572        NaN        NaN        NaN        NaN        NaN   \n",
            "4            2.572        NaN        NaN        NaN        NaN        NaN   \n",
            "...            ...        ...        ...        ...        ...        ...   \n",
            "423320       3.582     549.89     940.93      86.00     106.47    1530.56   \n",
            "423321       3.669     346.31    1377.41      93.40     140.32    2147.06   \n",
            "423322       3.620    1394.82     138.71      12.00     970.77    6859.07   \n",
            "423323       3.620     178.00      11.86        NaN        NaN     779.32   \n",
            "423324       3.804     212.02     851.73       2.06      10.88    1864.57   \n",
            "\n",
            "               CPI  Unemployment  IsHoliday_y  Year  Monthno  MarkDownOn  \n",
            "0       211.096358         8.106        False  2010        2       False  \n",
            "1       211.096358         8.106        False  2010        2       False  \n",
            "2       211.096358         8.106        False  2010        2       False  \n",
            "3       211.096358         8.106        False  2010        2       False  \n",
            "4       211.096358         8.106        False  2010        2       False  \n",
            "...            ...           ...          ...   ...      ...         ...  \n",
            "423320         NaN           NaN        False  2013        7        True  \n",
            "423321         NaN           NaN        False  2013        7        True  \n",
            "423322         NaN           NaN        False  2013        7        True  \n",
            "423323         NaN           NaN        False  2013        7        True  \n",
            "423324         NaN           NaN        False  2013        7        True  \n",
            "\n",
            "[423325 rows x 18 columns]\n"
          ]
        }
      ],
      "source": [
        "#merge sales and features datasets outer join on Store and Data\n",
        "# takes about 1min to run try not to run unless necessary\n",
        "df_salesfeaturesmerged = pd.merge(df_sales_T, df_features_T, how='outer', on=['Store', 'Date'])\n",
        "print(df_salesfeaturesmerged)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "No Nulls in the sales and stores datasets but in the features dataset, many of the 5 markdown columns have no data, but I'm unclear if this matters for many weeks as this may not be when any markdown would normally occur any way.  To assess this, I need to understand when these markdowns typically occur.\n",
        "\n",
        "According to the data source.\n",
        "https://www.kaggle.com/datasets/manjeetsingh/retaildataset\n",
        "\n",
        "'The company also runs several promotional markdown events throughout the year. These markdowns precede prominent holidays, the four largest of which are the Super Bowl, Labor Day, Thanksgiving, and Christmas. The weeks including these holidays are weighted five times higher in the evaluation than non-holiday weeks.'\n",
        "\n",
        "So the main 4 holiday periods are Super Bowl, Labor Day, Thanksgiving and Christmas\n",
        "\n",
        "According to Wikipedia\n",
        "https://en.wikipedia.org/wiki/Super_Bowl\n",
        "\n",
        "'Since 2022, the game has been played on the second Sunday in February. Prior Super Bowls were played on Sundays in early to mid-January from 1967 to 1978, late January from 1979 to 2003,[a] and the first Sunday of February from 2004 to 2021.'\n",
        "\n",
        "So would have been 1st Sun in Feb in all time periods above.\n",
        "\n",
        "According to Wikipedia\n",
        "https://en.wikipedia.org/wiki/Labor_Day\n",
        "\n",
        "'Labor Day is a federal holiday in the United States celebrated on the first Monday of September'\n",
        "\n",
        "According to a CoPilot search asking \n",
        "'When is thanksgiving celebrated in the USA?'\n",
        "https://www.bing.com/search?q=When%20is%20thanksgiving%20celebrated%20in%20the%20USA%3F&qs=n&form=QBRE&sp=-1&ghc=1&lq=0&pq=when%20is%20thanksgiving%20celebrated%20in%20the%20usa%3F&sc=19-43&sk=&cvid=A45308B981654BBCB1DA8924DA4332B2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              Weekly_Sales  MarkDown1  MarkDown2  MarkDown3  MarkDown4  \\\n",
            "Year Monthno                                                             \n",
            "2010 2               11839          0          0          0          0   \n",
            "     3               11788          0          0          0          0   \n",
            "     4               14697          0          0          0          0   \n",
            "     5               11672          0          0          0          0   \n",
            "     6               11661          0          0          0          0   \n",
            "     7               14561          0          0          0          0   \n",
            "     8               11603          0          0          0          0   \n",
            "     9               11724          0          0          0          0   \n",
            "     10              14667          0          0          0          0   \n",
            "     11              11712          0          0          0          0   \n",
            "     12              14755          0          0          0          0   \n",
            "2011 1               11695          0          0          0          0   \n",
            "     2               11741          0          0          0          0   \n",
            "     3               11813          0          0          0          0   \n",
            "     4               14746          0          0          0          0   \n",
            "     5               11820          0          0          0          0   \n",
            "     6               11723          0          0          0          0   \n",
            "     7               14621          0          0          0          0   \n",
            "     8               11765          0          0          0          0   \n",
            "     9               14761          0          0          0          0   \n",
            "     10              11820          0          0          0          0   \n",
            "     11              11901       8898       8347       8418       7692   \n",
            "     12              15047      14802      11807      14698      13350   \n",
            "2012 1               11850      11850      11798      10200      10387   \n",
            "     2               11946      11946      11898      10672      10969   \n",
            "     3               14850      14802      14070      13278      13379   \n",
            "     4               11889      11889       8148      11393      10617   \n",
            "     5               11822      11768        789      11005      10390   \n",
            "     6               14753      14706      11901      10766      13125   \n",
            "     7               11798      11798       9877      11400      10309   \n",
            "     8               14801      14646      11662      14067      13924   \n",
            "     9               11854      11802       7992      10418      10704   \n",
            "     10              11875      11774       2959      10776      10121   \n",
            "     11                  0        224        166        209        194   \n",
            "     12                  0        180         67        168        153   \n",
            "2013 1                   0        180        180        148        147   \n",
            "     2                   0        180        179        155        167   \n",
            "     3                   0        225         80        198        198   \n",
            "     4                   0        180        132        160        150   \n",
            "     5                   0        225        181        213        186   \n",
            "     6                   0        179        148        154        153   \n",
            "     7                   0        179        151        162        151   \n",
            "\n",
            "              MarkDown5  \n",
            "Year Monthno             \n",
            "2010 2                0  \n",
            "     3                0  \n",
            "     4                0  \n",
            "     5                0  \n",
            "     6                0  \n",
            "     7                0  \n",
            "     8                0  \n",
            "     9                0  \n",
            "     10               0  \n",
            "     11               0  \n",
            "     12               0  \n",
            "2011 1                0  \n",
            "     2                0  \n",
            "     3                0  \n",
            "     4                0  \n",
            "     5                0  \n",
            "     6                0  \n",
            "     7                0  \n",
            "     8                0  \n",
            "     9                0  \n",
            "     10               0  \n",
            "     11            8947  \n",
            "     12           15047  \n",
            "2012 1            11850  \n",
            "     2            11946  \n",
            "     3            14850  \n",
            "     4            11889  \n",
            "     5            11822  \n",
            "     6            14753  \n",
            "     7            11798  \n",
            "     8            14801  \n",
            "     9            11854  \n",
            "     10           11875  \n",
            "     11             225  \n",
            "     12             180  \n",
            "2013 1              180  \n",
            "     2              180  \n",
            "     3              225  \n",
            "     4              180  \n",
            "     5              225  \n",
            "     6              180  \n",
            "     7              180  \n"
          ]
        }
      ],
      "source": [
        "print((df_salesfeaturesmerged[['Year','Monthno','Weekly_Sales',\n",
        "'MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5']].groupby(['Year', 'Monthno']).count())\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2010 2011 2012 2013]\n",
            "\n",
            "Correlation matrix for 2010:\n",
            "                  Date  Weekly_Sales  IsHoliday_x  Temperature  Fuel_Price  \\\n",
            "Date          1.000000      0.026700     0.146391     0.055052    0.250063   \n",
            "Weekly_Sales  0.026700      1.000000     0.009637    -0.015941    0.049616   \n",
            "IsHoliday_x   0.146391      0.009637     1.000000    -0.209457    0.042079   \n",
            "Temperature   0.055052     -0.015941    -0.209457     1.000000   -0.170057   \n",
            "Fuel_Price    0.250063      0.049616     0.042079    -0.170057    1.000000   \n",
            "MarkDown1          NaN           NaN          NaN          NaN         NaN   \n",
            "MarkDown2          NaN           NaN          NaN          NaN         NaN   \n",
            "MarkDown3          NaN           NaN          NaN          NaN         NaN   \n",
            "MarkDown4          NaN           NaN          NaN          NaN         NaN   \n",
            "MarkDown5          NaN           NaN          NaN          NaN         NaN   \n",
            "CPI           0.008004     -0.024879     0.001149     0.155282   -0.586773   \n",
            "Unemployment -0.022399     -0.015378     0.001209     0.152018    0.390668   \n",
            "IsHoliday_y   0.146391      0.009637     1.000000    -0.209457    0.042079   \n",
            "Year               NaN           NaN          NaN          NaN         NaN   \n",
            "\n",
            "              MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5       CPI  \\\n",
            "Date                NaN        NaN        NaN        NaN        NaN  0.008004   \n",
            "Weekly_Sales        NaN        NaN        NaN        NaN        NaN -0.024879   \n",
            "IsHoliday_x         NaN        NaN        NaN        NaN        NaN  0.001149   \n",
            "Temperature         NaN        NaN        NaN        NaN        NaN  0.155282   \n",
            "Fuel_Price          NaN        NaN        NaN        NaN        NaN -0.586773   \n",
            "MarkDown1           NaN        NaN        NaN        NaN        NaN       NaN   \n",
            "MarkDown2           NaN        NaN        NaN        NaN        NaN       NaN   \n",
            "MarkDown3           NaN        NaN        NaN        NaN        NaN       NaN   \n",
            "MarkDown4           NaN        NaN        NaN        NaN        NaN       NaN   \n",
            "MarkDown5           NaN        NaN        NaN        NaN        NaN       NaN   \n",
            "CPI                 NaN        NaN        NaN        NaN        NaN  1.000000   \n",
            "Unemployment        NaN        NaN        NaN        NaN        NaN -0.345087   \n",
            "IsHoliday_y         NaN        NaN        NaN        NaN        NaN  0.001149   \n",
            "Year                NaN        NaN        NaN        NaN        NaN       NaN   \n",
            "\n",
            "              Unemployment  IsHoliday_y  Year  \n",
            "Date             -0.022399     0.146391   NaN  \n",
            "Weekly_Sales     -0.015378     0.009637   NaN  \n",
            "IsHoliday_x       0.001209     1.000000   NaN  \n",
            "Temperature       0.152018    -0.209457   NaN  \n",
            "Fuel_Price        0.390668     0.042079   NaN  \n",
            "MarkDown1              NaN          NaN   NaN  \n",
            "MarkDown2              NaN          NaN   NaN  \n",
            "MarkDown3              NaN          NaN   NaN  \n",
            "MarkDown4              NaN          NaN   NaN  \n",
            "MarkDown5              NaN          NaN   NaN  \n",
            "CPI              -0.345087     0.001149   NaN  \n",
            "Unemployment      1.000000     0.001209   NaN  \n",
            "IsHoliday_y       0.001209     1.000000   NaN  \n",
            "Year                   NaN          NaN   NaN  \n",
            "\n",
            "Correlation matrix for 2011:\n",
            "                  Date  Weekly_Sales  IsHoliday_x  Temperature  Fuel_Price  \\\n",
            "Date          1.000000      0.040466     0.170681     0.208039    0.104027   \n",
            "Weekly_Sales  0.040466      1.000000     0.017635    -0.001434    0.002740   \n",
            "IsHoliday_x   0.170681      0.017635     1.000000    -0.154454   -0.175076   \n",
            "Temperature   0.208039     -0.001434    -0.154454     1.000000    0.488436   \n",
            "Fuel_Price    0.104027      0.002740    -0.175076     0.488436    1.000000   \n",
            "MarkDown1    -0.359776      0.046927    -0.241360     0.061393    0.259887   \n",
            "MarkDown2     0.383333     -0.006026     0.506503    -0.138893   -0.112563   \n",
            "MarkDown3    -0.219216      0.096027     0.577728     0.129667    0.130694   \n",
            "MarkDown4    -0.339465      0.018197    -0.310193     0.088955    0.310369   \n",
            "MarkDown5    -0.120467      0.061857    -0.331505     0.063406    0.105575   \n",
            "CPI           0.035466     -0.018154     0.005696     0.198032   -0.330376   \n",
            "Unemployment -0.084474     -0.036788    -0.013115     0.142020    0.170578   \n",
            "IsHoliday_y   0.170681      0.017635     1.000000    -0.154454   -0.175076   \n",
            "Year               NaN           NaN          NaN          NaN         NaN   \n",
            "\n",
            "              MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5       CPI  \\\n",
            "Date          -0.359776   0.383333  -0.219216  -0.339465  -0.120467  0.035466   \n",
            "Weekly_Sales   0.046927  -0.006026   0.096027   0.018197   0.061857 -0.018154   \n",
            "IsHoliday_x   -0.241360   0.506503   0.577728  -0.310193  -0.331505  0.005696   \n",
            "Temperature    0.061393  -0.138893   0.129667   0.088955   0.063406  0.198032   \n",
            "Fuel_Price     0.259887  -0.112563   0.130694   0.310369   0.105575 -0.330376   \n",
            "MarkDown1      1.000000   0.173103  -0.246560   0.627302   0.270402 -0.090291   \n",
            "MarkDown2      0.173103   1.000000  -0.158063   0.023273  -0.170034 -0.039882   \n",
            "MarkDown3     -0.246560  -0.158063   1.000000  -0.215189  -0.147488 -0.044723   \n",
            "MarkDown4      0.627302   0.023273  -0.215189   1.000000   0.488792 -0.127088   \n",
            "MarkDown5      0.270402  -0.170034  -0.147488   0.488792   1.000000 -0.070509   \n",
            "CPI           -0.090291  -0.039882  -0.044723  -0.127088  -0.070509  1.000000   \n",
            "Unemployment   0.040234  -0.009903  -0.039068   0.163255   0.039804 -0.251300   \n",
            "IsHoliday_y   -0.241360   0.506503   0.577728  -0.310193  -0.331505  0.005696   \n",
            "Year                NaN        NaN        NaN        NaN        NaN       NaN   \n",
            "\n",
            "              Unemployment  IsHoliday_y  Year  \n",
            "Date             -0.084474     0.170681   NaN  \n",
            "Weekly_Sales     -0.036788     0.017635   NaN  \n",
            "IsHoliday_x      -0.013115     1.000000   NaN  \n",
            "Temperature       0.142020    -0.154454   NaN  \n",
            "Fuel_Price        0.170578    -0.175076   NaN  \n",
            "MarkDown1         0.040234    -0.241360   NaN  \n",
            "MarkDown2        -0.009903     0.506503   NaN  \n",
            "MarkDown3        -0.039068     0.577728   NaN  \n",
            "MarkDown4         0.163255    -0.310193   NaN  \n",
            "MarkDown5         0.039804    -0.331505   NaN  \n",
            "CPI              -0.251300     0.005696   NaN  \n",
            "Unemployment      1.000000    -0.013115   NaN  \n",
            "IsHoliday_y      -0.013115     1.000000   NaN  \n",
            "Year                   NaN          NaN   NaN  \n",
            "\n",
            "Correlation matrix for 2012:\n",
            "                  Date  Weekly_Sales  IsHoliday_x  Temperature  Fuel_Price  \\\n",
            "Date          1.000000      0.004763    -0.019075     0.596504    0.253865   \n",
            "Weekly_Sales  0.004763      1.000000     0.007871     0.015335    0.007246   \n",
            "IsHoliday_x  -0.019075      0.007871     1.000000    -0.058975   -0.032271   \n",
            "Temperature   0.596504      0.015335    -0.058975     1.000000    0.107455   \n",
            "Fuel_Price    0.253865      0.007246    -0.032271     0.107455    1.000000   \n",
            "MarkDown1    -0.139483      0.103443     0.061129    -0.117337   -0.015309   \n",
            "MarkDown2    -0.466646      0.030867     0.013177    -0.455289   -0.239647   \n",
            "MarkDown3     0.029747      0.070726     0.040698    -0.018815   -0.012076   \n",
            "MarkDown4    -0.180390      0.059534     0.087226    -0.132348   -0.124890   \n",
            "MarkDown5     0.009077      0.092138     0.020192     0.030099   -0.108404   \n",
            "CPI           0.014323     -0.017729    -0.000795     0.179474   -0.418629   \n",
            "Unemployment -0.084975     -0.035691     0.003020     0.044003    0.326444   \n",
            "IsHoliday_y  -0.012975      0.007871     1.000000    -0.061606   -0.034781   \n",
            "Year               NaN           NaN          NaN          NaN         NaN   \n",
            "\n",
            "              MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5       CPI  \\\n",
            "Date          -0.139483  -0.466646   0.029747  -0.180390   0.009077  0.014323   \n",
            "Weekly_Sales   0.103443   0.030867   0.070726   0.059534   0.092138 -0.017729   \n",
            "IsHoliday_x    0.061129   0.013177   0.040698   0.087226   0.020192 -0.000795   \n",
            "Temperature   -0.117337  -0.455289  -0.018815  -0.132348   0.030099  0.179474   \n",
            "Fuel_Price    -0.015309  -0.239647  -0.012076  -0.124890  -0.108404 -0.418629   \n",
            "MarkDown1      1.000000   0.048264   0.000999   0.828396   0.165067 -0.055828   \n",
            "MarkDown2      0.048264   1.000000   0.006440   0.046484   0.063276 -0.048690   \n",
            "MarkDown3      0.000999   0.006440   1.000000   0.001607  -0.003170 -0.003239   \n",
            "MarkDown4      0.828396   0.046484   0.001607   1.000000   0.102884 -0.049838   \n",
            "MarkDown5      0.165067   0.063276  -0.003170   0.102884   1.000000  0.087597   \n",
            "CPI           -0.055828  -0.048690  -0.003239  -0.049838   0.087597  1.000000   \n",
            "Unemployment   0.068465   0.012067  -0.003274   0.029684  -0.026304 -0.284338   \n",
            "IsHoliday_y    0.059809   0.020637   0.074455   0.085182   0.017049 -0.000671   \n",
            "Year                NaN        NaN        NaN        NaN        NaN       NaN   \n",
            "\n",
            "              Unemployment  IsHoliday_y  Year  \n",
            "Date             -0.084975    -0.012975   NaN  \n",
            "Weekly_Sales     -0.035691     0.007871   NaN  \n",
            "IsHoliday_x       0.003020     1.000000   NaN  \n",
            "Temperature       0.044003    -0.061606   NaN  \n",
            "Fuel_Price        0.326444    -0.034781   NaN  \n",
            "MarkDown1         0.068465     0.059809   NaN  \n",
            "MarkDown2         0.012067     0.020637   NaN  \n",
            "MarkDown3        -0.003274     0.074455   NaN  \n",
            "MarkDown4         0.029684     0.085182   NaN  \n",
            "MarkDown5        -0.026304     0.017049   NaN  \n",
            "CPI              -0.284338    -0.000671   NaN  \n",
            "Unemployment      1.000000     0.002414   NaN  \n",
            "IsHoliday_y       0.002414     1.000000   NaN  \n",
            "Year                   NaN          NaN   NaN  \n",
            "\n",
            "Correlation matrix for 2013:\n",
            "                  Date  Weekly_Sales  IsHoliday_x  Temperature  Fuel_Price  \\\n",
            "Date          1.000000           NaN          NaN     0.791970    0.234863   \n",
            "Weekly_Sales       NaN           NaN          NaN          NaN         NaN   \n",
            "IsHoliday_x        NaN           NaN          NaN          NaN         NaN   \n",
            "Temperature   0.791970           NaN          NaN     1.000000    0.090522   \n",
            "Fuel_Price    0.234863           NaN          NaN     0.090522    1.000000   \n",
            "MarkDown1    -0.222872           NaN          NaN    -0.220013    0.060270   \n",
            "MarkDown2    -0.396386           NaN          NaN    -0.330441   -0.154556   \n",
            "MarkDown3     0.125617           NaN          NaN     0.088050    0.085127   \n",
            "MarkDown4    -0.163072           NaN          NaN    -0.121036   -0.013787   \n",
            "MarkDown5    -0.004733           NaN          NaN     0.053481   -0.081709   \n",
            "CPI           0.006715           NaN          NaN     0.272894   -0.395140   \n",
            "Unemployment -0.031242           NaN          NaN     0.050165    0.410099   \n",
            "IsHoliday_y  -0.203815           NaN          NaN    -0.146414   -0.036096   \n",
            "Year               NaN           NaN          NaN          NaN         NaN   \n",
            "\n",
            "              MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5       CPI  \\\n",
            "Date          -0.222872  -0.396386   0.125617  -0.163072  -0.004733  0.006715   \n",
            "Weekly_Sales        NaN        NaN        NaN        NaN        NaN       NaN   \n",
            "IsHoliday_x         NaN        NaN        NaN        NaN        NaN       NaN   \n",
            "Temperature   -0.220013  -0.330441   0.088050  -0.121036   0.053481  0.272894   \n",
            "Fuel_Price     0.060270  -0.154556   0.085127  -0.013787  -0.081709 -0.395140   \n",
            "MarkDown1      1.000000  -0.054094   0.219129   0.823845   0.325575 -0.035017   \n",
            "MarkDown2     -0.054094   1.000000  -0.101269  -0.086029   0.040633 -0.058203   \n",
            "MarkDown3      0.219129  -0.101269   1.000000   0.204859   0.070265 -0.051171   \n",
            "MarkDown4      0.823845  -0.086029   0.204859   1.000000   0.203496 -0.075840   \n",
            "MarkDown5      0.325575   0.040633   0.070265   0.203496   1.000000  0.097418   \n",
            "CPI           -0.035017  -0.058203  -0.051171  -0.075840   0.097418  1.000000   \n",
            "Unemployment   0.025282  -0.002624  -0.035019   0.029084  -0.014548 -0.275197   \n",
            "IsHoliday_y    0.669326  -0.066538   0.088464   0.589855   0.068009 -0.001187   \n",
            "Year                NaN        NaN        NaN        NaN        NaN       NaN   \n",
            "\n",
            "              Unemployment  IsHoliday_y  Year  \n",
            "Date             -0.031242    -0.203815   NaN  \n",
            "Weekly_Sales           NaN          NaN   NaN  \n",
            "IsHoliday_x            NaN          NaN   NaN  \n",
            "Temperature       0.050165    -0.146414   NaN  \n",
            "Fuel_Price        0.410099    -0.036096   NaN  \n",
            "MarkDown1         0.025282     0.669326   NaN  \n",
            "MarkDown2        -0.002624    -0.066538   NaN  \n",
            "MarkDown3        -0.035019     0.088464   NaN  \n",
            "MarkDown4         0.029084     0.589855   NaN  \n",
            "MarkDown5        -0.014548     0.068009   NaN  \n",
            "CPI              -0.275197    -0.001187   NaN  \n",
            "Unemployment      1.000000     0.005887   NaN  \n",
            "IsHoliday_y       0.005887     1.000000   NaN  \n",
            "Year                   NaN          NaN   NaN  \n"
          ]
        }
      ],
      "source": [
        "#Correlation matriced for total sales vs other numerical values in features dataset in each year\n",
        "\n",
        "years= df_salesfeaturesmerged['Year'].unique()\n",
        "print (years)\n",
        "for y in years:\n",
        "\n",
        "    print()\n",
        "    print(f'Correlation matrix for {y}:')\n",
        "    print(df_salesfeaturesmerged[df_salesfeaturesmerged['Year'] == y].drop(columns=['Monthno', 'Store', 'Dept', 'MarkDownOn']).corr())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#commenting out code to reduce file size\n",
        "\n",
        "# #timeline Markdowns line plot\n",
        "# df_features.plot(kind='line', x='Date', y=['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5'], figsize=(10, 5), title='Markdowns Timeline')\n",
        "# plt.show()\n",
        "# # .plot(kind='line',x='year',y='AvgLevels', figsize=(5,5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#commenting out code to reduce file size\n",
        "\n",
        "# #salesfeaturemerged Markdowns and sales timeline plot from 2011 and 2012 \n",
        "# # the only years where sales and markdown datasets overlap\n",
        "# for y in [2011, 2012]:\n",
        "#     df_salesfeaturesmerged.query('Year==@y').plot(kind='line', x='Date', y=['Weekly_Sales', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5'], figsize=(10, 5), title=f'Markdowns Timeline {y}')\n",
        "#     plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#My internet is down phone and ask Vasi if working locally is a good alrernative.  His tel number is"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_salesfeaturesmerged[['Year','Monthno','Weekly_Sales','MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5']].groupby(['Year', 'Monthno']).count())\n",
        "\n",
        "# I see there is sales data from Jan 2010 until Dec 2012  \n",
        "# The Kaggle sourcepage said there was in fact no sales data until Feb 2011 so was worth checking."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In cases where you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "#I don't understand what's going on in the template code below \n",
        "# which generates errors with each run, so commented out for now.\n",
        "\n",
        "# import os\n",
        "# try:\n",
        "#   # create your folder here\n",
        "#   # os.makedirs(name='')\n",
        "# except Exception as e:\n",
        "#   print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
